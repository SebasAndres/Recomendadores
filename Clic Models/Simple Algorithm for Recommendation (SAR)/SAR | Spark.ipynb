{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0ed2f8c",
   "metadata": {},
   "source": [
    "# Implementacion del SAR | Spark.\n",
    "\n",
    "Armo matrices de Similaridad Item-Item y Afinidad User-Item. Los scores son el resultado de multiplicar ambas.\n",
    "\n",
    "* [Diagrama](https://app.mural.co/invitation/mural/cabj9579/1687786596047?sender=uf8c4081d0c866c8eb2174164&key=2164d5d5-7bc5-478e-a090-da611bb616c2)\n",
    "\n",
    "<img src=\"img/diagrama-sar.png\">\n",
    "\n",
    "Este notebook tiene:\n",
    "\n",
    "* 1. Lectura de datos\n",
    "\n",
    "* 2. Implementacion del SAR (#BUILD):\n",
    "   \n",
    "   > [a] Armado de indices.<br>\n",
    "   > [b] Armado de diccionario auxiliar para C.<br>\n",
    "   > [c] Armado de matriz de co-ocurrencia.<br>  \n",
    "   > [d] Armado de matriz de similaridad.<br>   \n",
    "   > [e] Armado de matriz de afinidad.<br>\n",
    "   > [f] Predicciones.<br>\n",
    "   \n",
    "* 3. Recomendaciones:\n",
    "    > [a] Items populares.<br> \n",
    "    > [b] Items dado un usuario.<br>    \n",
    "    > [c] Items dado un item.<br>\n",
    "\n",
    "* 4. Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f232e920",
   "metadata": {},
   "source": [
    "## [0] Importo librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167871e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, DataFrame\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import split, explode, monotonically_increasing_id\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39da6462",
   "metadata": {},
   "source": [
    "## [1] Lectura de datos\n",
    "\n",
    "* Leo el df (pyspark.DataFrame) y armo un dataset como subconjunto fijo de ese df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c11877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leo el dataframe\n",
    "load_options = {\"table\": \"view_events\", \"keyspace\": \"clarovideo\"}\n",
    "df = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**load_options).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7526255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(user_id=39407448, event='view', event_time=datetime.datetime(2023, 5, 14, 2, 55, 56), group_id=1039138),\n",
       " Row(user_id=77488189, event='view', event_time=datetime.datetime(2023, 5, 15, 18, 44, 18), group_id=967246),\n",
       " Row(user_id=39796339, event='view', event_time=datetime.datetime(2023, 5, 20, 17, 2, 12), group_id=929874),\n",
       " Row(user_id=80962217, event='view', event_time=datetime.datetime(2023, 5, 18, 17, 46, 7), group_id=1079184),\n",
       " Row(user_id=51166585, event='view', event_time=datetime.datetime(2023, 5, 23, 2, 46, 8), group_id=1115324)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# muestra\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b742c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2927260"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamaño del dataset\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc68aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# armo un dataset, como subconjunto del df \n",
    "test, train = df.randomSplit([0.20, 0.80],seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e4bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2342413"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = train\n",
    "dataset.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdd0975e",
   "metadata": {},
   "source": [
    "## [2.a] Armado de índices:\n",
    "\n",
    "* Necesito asociar group_ids y user_ids a posiciones en las matrices.\n",
    "* Ademas, aprovecho para leer la metadata de los group_ids."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7869379",
   "metadata": {},
   "source": [
    "### Levanto los indices preexistentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09178da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemIndexes() -> dict:\n",
    "    file = open('tmp/item_indexes.json' , mode='r' , encoding='utf8')\n",
    "    content_key_str:dict = json.load(file)\n",
    "    return {int(k):v for k,v in content_key_str.items()}\n",
    "\n",
    "def getUserIndexes() -> dict:\n",
    "    file = open('tmp/user_indexes.json' , mode='r' , encoding='utf8')\n",
    "    content_key_str:dict = json.load(file)\n",
    "    return {int(k):v for k,v in content_key_str.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a112e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemIndexes:dict = getItemIndexes()\n",
    "userIndexes:dict = getUserIndexes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cdb460f",
   "metadata": {},
   "source": [
    "### Agrego los usuarios e items del dataset que no estan registrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ebd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_interaction(interaction:pyspark.sql.types.Row) -> tuple:\n",
    "    # Dada una interaccion, devuelve la tripla (user_id, group_id, event_time)    \n",
    "    d = interaction.asDict()\n",
    "    return d[\"user_id\"], d[\"group_id\"], d[\"event_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b3787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetadata(group_id:int) -> dict():\n",
    "    \n",
    "    # Dado un group id, devuelve la metadata necesaria\n",
    "    # para filtrar y potenciar contenido\n",
    "    \n",
    "    # Elastic con la metadata\n",
    "    elastic_host:str = \"host_donde_esta_la_metadata\"     \n",
    "    url:str = f\"{elastic_host}/metadata/_doc/{group_id}\"\n",
    "\n",
    "    metadata:dict = dict() # respuesta    \n",
    "\n",
    "    try:\n",
    "        resp:dict = requests.get(url=url).json()\n",
    "        if not resp['found']:\n",
    "            # print(group_id, \"not found\")\n",
    "            # mandar a popular\n",
    "            pass\n",
    "        else:\n",
    "            filtros:list = resp[\"_source\"][\"infoFiltros\"] \n",
    "            metadata.update({\"filtros\": filtros})\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6483411",
   "metadata": {},
   "source": [
    "### (Version 1) Usuarios e item en el mismo recorrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef4e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_items_and_users(dataset:DataFrame, existing_users:dict, existing_items:dict):\n",
    "    \n",
    "    info:dict = { \"missing_metadata\": set(), \"ignored_users\": set() }\n",
    "    dataset_ls = dataset.collect()\n",
    "    \n",
    "    for j in trange(len(dataset_ls)):\n",
    "        \n",
    "        interaction = dataset_ls[j]\n",
    "        user_id, group_id, event_time = decode_interaction(interaction)\n",
    "        \n",
    "        # Agrego nuevo usuario\n",
    "        if user_id not in existing_users.keys():            \n",
    "            u_index = len(existing_users) # index del nuevo usuario\n",
    "            existing_users.update({user_id:u_index})\n",
    "        \n",
    "        else:\n",
    "            info[\"ignored_users\"].add(user_id)\n",
    "            \n",
    "        # Agrego nuevo item\n",
    "        if group_id not in existing_items.keys():\n",
    "            i_index = len(existing_items) # index del nuevo item           \n",
    "            metadata = getMetadata(group_id)\n",
    "            \n",
    "            if metadata == dict():\n",
    "                info[\"missing_metadata\"].add(group_id)\n",
    "        \n",
    "            else:\n",
    "                existing_items.update({\n",
    "                    group_id:{\n",
    "                        \"index\": i_index,\n",
    "                        \"metadata\": metadata\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "        pass\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7c5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = read_items_and_users(dataset, userIndexes, itemIndexes)\n",
    "# [9:20:36<254:33:38, 2.44it/s] !! (9hs para 106319 datos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f13b42ee",
   "metadata": {},
   "source": [
    "### (Version 2) Usuarios e items por separado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e2aece",
   "metadata": {},
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b75ba439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNewItems(dataset:DataFrame,\n",
    "                 existing_items:dict) -> dict():\n",
    "    \n",
    "    # Dado un dataset y un diccionario con los indices de item preexistentes,\n",
    "    # agrega al indice los items del dataset que no estaban previamente\n",
    "    \n",
    "    # informacion de los datos perdidos\n",
    "    info:dict = { \"missing_metadata\": [] }\n",
    "\n",
    "    set_items = set([i.group_id for i in dataset.select(\"group_id\").collect()])\n",
    "    items_lss = list(set_items)\n",
    "    \n",
    "    for j in trange(len(set_items)):\n",
    "        itemid = items_lss[j] \n",
    "        \n",
    "        if itemid not in existing_items.keys():\n",
    "            \n",
    "            # el index es por aparicion\n",
    "            index = len(existing_items)\n",
    "            \n",
    "            # leo la metadata segun el group_id\n",
    "            metadata = getMetadata(itemid)\n",
    "            \n",
    "            if metadata == dict():\n",
    "                # skip\n",
    "                info[\"missing_metadata\"].append(itemid)\n",
    "        \n",
    "            else:\n",
    "                existing_items.update({\n",
    "                    itemid:{\n",
    "                        \"index\": index,\n",
    "                        \"metadata\": metadata\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a5b491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = readNewItems(dataset, itemIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "990fbda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* N° de items únicos:  9783\n",
      "* Items omitidos:  19172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===================================================>     (9 + 1) / 10]\r"
     ]
    }
   ],
   "source": [
    "print(\"* N° de items únicos: \", len(itemIndexes.keys()))\n",
    "print(\"* Items omitidos: \", len(info[\"missing_metadata\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c03c236",
   "metadata": {},
   "source": [
    "### Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "920d2573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def readNewUsers(dataset:DataFrame,\n",
    "                 existing_users:dict) -> tuple:\n",
    "    \n",
    "    # Dado un dataset y una lista de indices de usuarios existente,\n",
    "    # Agrega a esta todos los usuarios de dataset que no estan en el dict\n",
    "        \n",
    "    set_usuarios:set = set([u.user_id for u in dataset.select(\"user_id\").collect()])\n",
    "    usuarios_lss:list = list(set_usuarios)\n",
    "    \n",
    "    contador:int = 0 # cantidad de user_ids ignorados\n",
    "    \n",
    "    for i in trange(len(set_usuarios)):\n",
    "        userid = usuarios_lss[i]\n",
    "        if userid not in existing_users.keys():\n",
    "            index = len(existing_users)\n",
    "            existing_users.update({userid:index})\n",
    "        else:\n",
    "            contador += 1\n",
    "    \n",
    "    return set_usuarios, contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6f5c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:533)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a225d51d5e94cadb14d7738cea88e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/496442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_usuarios, ignored_users = readNewUsers(dataset, userIndexes) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53175d26",
   "metadata": {},
   "source": [
    "### Guardo los indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d3367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizarDocsIndices(itemIndexes, userIndexes):\n",
    "    # actualizo item_indexes\n",
    "    with open(\"tmp/item_indexes.json\", \"w\") as file:\n",
    "        json.dump(itemIndexes, file, indent=2)\n",
    "    \n",
    "    # actualizo user_indexes\n",
    "    with open(\"tmp/user_indexes.json\", \"w\") as file:\n",
    "        json.dump(userIndexes, file, indent=2)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3215e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualizarDocsIndices(itemIndexes, userIndexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd143b8d",
   "metadata": {},
   "source": [
    "## [2.b] Armo un diccionario auxiliar para armar la Co-ocurrence Matrix ($C$):\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b52d87ed",
   "metadata": {},
   "source": [
    "### C como matriz CSR ~ Item viewers\n",
    "\n",
    "> {item_id: [user_id, user_id, ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe32437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_viewers(dataset:DataFrame) -> dict():\n",
    "    \n",
    "    # Dado un dataset, y una lista de item_ids presentes en él\n",
    "    # devuelve un diccionario con { item_id: [user_id, ---, user_id] }\n",
    "    # siendo esta lista los usuarios que vieron item_id en ese dataset\n",
    "    \n",
    "    items_viewers:dict = dict()\n",
    "    dataset_ls:list = dataset.collect()\n",
    "    \n",
    "    for i in trange(len(dataset_ls)):\n",
    "        \n",
    "        interaction = dataset_ls[i]\n",
    "        user_id, group_id, event_time = decode_interaction(interaction)\n",
    "        \n",
    "        if group_id in itemIndexes.keys():\n",
    "            if group_id in items_viewers.keys():\n",
    "                items_viewers[group_id].add(user_id)\n",
    "            else:\n",
    "                if group_id in itemIndexes.keys(): # si es un group_id valido    \n",
    "                    items_viewers.update({group_id:{user_id}})\n",
    "            \n",
    "    return items_viewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c123521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a710faa07ea4fa09bc33bbdabdf90c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2342154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items_viewers = build_item_viewers(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4315fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/items_viewers.json\", \"w\") as file:\n",
    "    _items_viewers = dict()\n",
    "    for k, v in items_viewers.items():\n",
    "        _items_viewers.update({k:list(v)})\n",
    "    json.dump(_items_viewers, file, indent=2)\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8101c894",
   "metadata": {},
   "source": [
    "### Como dataframe de spark ~ Users Histories\n",
    "\n",
    "> {user_id: [item_id, item_id, ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a229daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_histories(dataset:DataFrame) -> dict():\n",
    "       \n",
    "    users_histories:dict = dict()\n",
    "    dataset_ls:list = dataset.collect()\n",
    "    \n",
    "    for i in trange(len(dataset_ls)):\n",
    "        \n",
    "        interaction = dataset_ls[i]\n",
    "        user_id, group_id, event_time = decode_interaction(interaction)\n",
    "        \n",
    "        if user_id not in users_histories.keys():\n",
    "            users_histories.update({user_id: [group_id]})\n",
    "        else:\n",
    "            user_movies:set = set(users_histories[user_id])\n",
    "            user_movies.add(group_id)\n",
    "            users_histories[user_id] = list(user_movies)\n",
    "    \n",
    "    return users_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f80274cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 445:>                                                        (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d56d884fe1740bab561334c5402d2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_histories:dict = build_users_histories(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c9f0881",
   "metadata": {},
   "source": [
    "## [2.c] Co-ocurrence Matrix ($C$):\n",
    "\n",
    "* $S$ una matriz $C \\in \\Re^{MxM}$, en la que $C_{ij}$=\"# usuarios que vieron items i y j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1372b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCoocurrenceMatrix(itemIndexes:dict, items_viewers:dict) -> csr_matrix:\n",
    "    \n",
    "    # Dado el diccionario auxiliar users_per_item y \n",
    "    # el diccionario que asocia group_id con su indice en la matriz,\n",
    "    # devuelve la matriz de Coocurrencia C\n",
    "    \n",
    "    M:int = len(itemIndexes.keys()) # cantidad de items en el dataset y registrados\n",
    "    C:csr_matrix = csr_matrix((M,M)).tolil()\n",
    "        \n",
    "    print(\"* Armando matriz C...\")\n",
    "    \n",
    "    for i, item_i in enumerate(items_viewers.keys()):\n",
    "        \n",
    "        index_i:int = itemIndexes[item_i][\"index\"] # index del item i\n",
    "        item_i_viewers:set = items_viewers[item_i] # usuarios que vieron el item i\n",
    "\n",
    "        for j, item_j in enumerate(items_viewers.keys()):\n",
    "            \n",
    "            index_j:int = itemIndexes[item_j][\"index\"] # index del item j\n",
    "            item_j_viewers:set = items_viewers[item_j] # usuarios que vieron el item j\n",
    "            \n",
    "            C[index_j, index_i] = len(item_j_viewers.intersection(item_i_viewers))\n",
    "           \n",
    "    print(\"* Matriz creada ✔\")\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005d7619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Armando matriz C...\n",
      "* Matriz creada ✔\n"
     ]
    }
   ],
   "source": [
    "C = buildCoocurrenceMatrix(itemIndexes, items_viewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4496d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test exhaustivo de C\n",
    "\n",
    "ikeys = list(items_viewers.keys())\n",
    "for a in ikeys:\n",
    "    i = itemIndexes[a][\"index\"]    \n",
    "    for b in ikeys:\n",
    "        j = itemIndexes[b][\"index\"]\n",
    "        viewers_a = items_viewers[a]\n",
    "        viewers_b = items_viewers[b]\n",
    "        viewers_ab = len(viewers_a.intersection(viewers_b))        \n",
    "        if int(C[i,j]) != viewers_ab:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4bb0f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCoocurrenceMatrix_df(users_histories:dict) -> DataFrame:\n",
    "    \n",
    "    # Dado un dataset y un listado de las peliculas que vio cada usuario,  \n",
    "    # devuelve la matriz de Coocurrencia C como DataFrame\n",
    "    \n",
    "    # No respeta los indices puestos en itemIndexes\n",
    "    \n",
    "    ls_users_histories:list = list()\n",
    "    for user, movies in users_histories.items():\n",
    "        txt = str(movies)[1:-1]\n",
    "        ls_users_histories.append(txt)\n",
    "        \n",
    "    ddf = spark.createDataFrame(\n",
    "            ls_users_histories,\n",
    "            \"string\"\n",
    "          ).toDF(\"C\")\n",
    "\n",
    "    long = (ddf\n",
    "            .withColumn(\"id\", monotonically_increasing_id())\n",
    "            .select(\"id\", explode(split(\"C\", \",\"))))\n",
    "\n",
    "    C = long.withColumnRenamed(\"col\", \"col_\").join(long, [\"id\"]).stat.crosstab(\"col_\", \"col\")\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "71cbdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "C_df:DataFrame = buildCoocurrenceMatrix_df(users_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c64ae144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|1113875|\n",
      "+-------+\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      1|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "|      0|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_df.select('1113875').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc64dc3d",
   "metadata": {},
   "source": [
    "## [2.d] Item-Similarity Matrix ($S$):\n",
    "\n",
    "* $S \\in \\Re^{MxM}$  es el resultado de aplicar una métrica a la matriz de co-ocurrencia C.\n",
    "* Obs: Una metrica aceptada es dejar exactamente igual a C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5c2d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSimilarityMatrix(C:csr_matrix, metric=\"counts\") -> csr_matrix:\n",
    "    \n",
    "    if metric == \"counts\":\n",
    "        return C\n",
    "    \n",
    "    elif metric == \"jaccard\":\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "        \n",
    "    elif metric == \"lift\":\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "        \n",
    "S = buildSimilarityMatrix(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bc2d539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSimilarityMatrix_df(C:DataFrame, metric=\"counts\") -> DataFrame:\n",
    "    \n",
    "    # Aplico una metrica para C\n",
    "    \n",
    "    if metric==\"counts\":\n",
    "        return C \n",
    "    \n",
    "    elif metric==\"jaccard\":\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "        \n",
    "    elif metric==\"lift\":\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Metric not implemented\")\n",
    "        \n",
    "S_df:DataFrame = buildSimilarityMatrix(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3736859",
   "metadata": {},
   "source": [
    "## [2.e] User-Item Affinity Matrix ($A$):\n",
    "\n",
    "* $A_{ij} = \\sum_{k \\in dataset} W_k 2^{-(\\frac{t_0-t_k}{T})}$,\n",
    "\n",
    "Donde: \n",
    "\n",
    "- $k$ es un evento del dataset que involucra al usuario i y al item j, es decir, una visualizacion de i a j. \n",
    "- $t_0$ es el tiempo actual en una determinada unidad.\n",
    "- $t_k$ es el tiempo de la interaccion / evento k.\n",
    "\n",
    "Con parametros: \n",
    "- $T$ es un parametro en las mismas unidades de  $t_0$ y $t_k$. Los eventos T unidades antes de t_0 tienen la mitad del peso.\n",
    "- $W_k$ es un parametro que indica el peso del tipo de evento de k, en nuestro caso solo tenemos \"view\". $W_k = 1$\n",
    "\n",
    "Es decir, para nuestro caso puede quedar:\n",
    "\n",
    "* $A_{ij} = \\sum_{k} 2^{-(\\frac{t_0-t_k}{T})}$\n",
    "\n",
    "OBS: $A \\in \\Re^{N x M}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bb9b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualTimestamp() -> float:\n",
    "    return datetime.datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256aff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(event_time:datetime.datetime, T=(17/3)*10**8, W=1) -> float:\n",
    "\n",
    "    # Devuelve el scoring de un evento visto en la fecha pasada como argumento\n",
    "    # Teniendo como parametro a la constante T \n",
    "    \n",
    "    t_k = event_time.timestamp()\n",
    "    t_0 = actualTimestamp()\n",
    "    exp = - (t_0 - t_k) / T\n",
    "    \n",
    "    return W * 2 ** exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38414e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affinity_scores(dataset:DataFrame,\n",
    "                            verb=False) -> np.ndarray:\n",
    "    \n",
    "    # Dado un dataset,\n",
    "    # Recorre cada evento del dataset y\n",
    "    # suma su scoring en el respectivo indice de A\n",
    "    \n",
    "    global itemIndexes, userIndexes\n",
    "    \n",
    "    M = len(itemIndexes.keys())   \n",
    "    N = len(userIndexes.keys())\n",
    "    \n",
    "    A:csr_matrix = csr_matrix((N, M)).tolil()  \n",
    "    ignored_counter:int = 0\n",
    "    \n",
    "    for interaction in dataset.collect():\n",
    "        \n",
    "        user_id, group_id, event_time = decode_interaction(interaction)\n",
    "        \n",
    "        if group_id in itemIndexes.keys() and user_id in userIndexes.keys():\n",
    "            \n",
    "            index_item = itemIndexes[group_id][\"index\"]\n",
    "            index_user = userIndexes[user_id]\n",
    "\n",
    "            if verb:\n",
    "                print(index_user, index_item, event_time, scoring_function(event_time))\n",
    "\n",
    "            A[index_user, index_item] += scoring_function(event_time)\n",
    "            # pre_existing_value = readA(index_user, index_item)\n",
    "            # assign_A(scoring_function(event_time) + pre_existing_value)\n",
    "\n",
    "        else:\n",
    "            ignored_counter += 1\n",
    "    \n",
    "    pass\n",
    "        \n",
    "    return ignored_counter, A        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040cdf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ignored_interactions, A = compute_affinity_scores(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78800e07",
   "metadata": {},
   "source": [
    "## [2.f] Predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4407173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(A,S) -> np.ndarray:\n",
    "    return A @ S\n",
    "\n",
    "def rating(user_id:int,item_id:int) -> float:\n",
    "    \n",
    "    # Dado un user_id y un group_id\n",
    "    # devuelve el scoring que le da el user a ese contenido\n",
    "    # segun el modelo \n",
    "    \n",
    "    global itemIndexes, userIndexes\n",
    "    global preds \n",
    "        \n",
    "    user_index = userIndexes[user_id]\n",
    "    item_index = itemIndexes[item_id][\"index\"]\n",
    "    \n",
    "    return preds[user_index,item_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "62c3ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions(A,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1179e10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.768611047741935"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating(user_id=2784814, item_id=770988)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "145b0ac2",
   "metadata": {},
   "source": [
    "## [3.a] Recomendar items populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "053204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedItemIndexes = {v[\"index\"]: k for k, v in itemIndexes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47205cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestTuple(item2item:list) -> tuple:\n",
    "    if len(item2item) == 0:\n",
    "        raise Exception(\"La lista de tuplas debe tener al menos un elemento\")\n",
    "    else:\n",
    "        _max, _index = item2item[0]\n",
    "        for n_views, index in item2item[1:]:\n",
    "            if n_views > _max:\n",
    "                (_max, _index) = (n_views, index)\n",
    "        return _max, _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f1763e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopLMovies(preds:np.ndarray, L:int, exclude:list=[]) -> list:\n",
    "    \n",
    "    # devuelve las L peliculas/items mas populares exluyendo los group_ids en la lista exclude dada\n",
    "    # out = [(key1, \"popular\"), ..., (keyL, \"popular\")]\n",
    "    \n",
    "    global itemIndexes\n",
    "    global invertedItemIndexes\n",
    "    \n",
    "    if preds.shape[1] < L:\n",
    "        raise Exception(\"Y tiene menos peliculas de las necesarias\")\n",
    "    \n",
    "    item2item:list = []\n",
    "    for i in trange(preds.shape[1]):       \n",
    "        valoraciones = preds[:, i].toarray()\n",
    "        suma_valoraciones = sum(valoraciones.flatten())\n",
    "        item2item.append((suma_valoraciones, i))\n",
    "        \n",
    "    out:list = []\n",
    "           \n",
    "    while (len(out) < L):\n",
    "        n_views, index = getBestTuple(item2item)\n",
    "        group_id = invertedItemIndexes[index]\n",
    "        \n",
    "        if group_id not in exclude:\n",
    "            ## aca irian los filtros por metadata de que contenido puede ser                \n",
    "            out.append((group_id, \"popular\"))\n",
    "        \n",
    "        item2item.remove((n_views,index))\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd7ac09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getTopLMovies(preds,10, exclude=[]) # 1hs dura!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73e1afaf",
   "metadata": {},
   "source": [
    "## [3.b] Recomendar items dado un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78f99f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_k_items_to_user(preds:np.ndarray,\n",
    "                              user_id:int,\n",
    "                              k:int,\n",
    "                              include=[],\n",
    "                              enhance=[],\n",
    "                              exclude=[],\n",
    "                              bias=10\n",
    "                              )->np.ndarray:\n",
    "\n",
    "    global itemsIndexes, userIndexes\n",
    "    \n",
    "    user_index:int = userIndexes[user_id]\n",
    "    ratings_user:list = list(preds[0].toarray()[0])\n",
    "    \n",
    "    ## filtro y enhance\n",
    "    \"\"\"\n",
    "    for group_id in itemIndexes.keys():\n",
    "    \n",
    "        item:dict = itemIndexes[group_id]\n",
    "        metadata:dict = item[\"metadata\"]\n",
    "        ixd:int = item[\"index\"]\n",
    "         \n",
    "        if metadata == dict():\n",
    "            # si no pude leer los filtros\n",
    "            # asumo que es contenido invalido\n",
    "            ratings_user[idx] = -1\n",
    "        \n",
    "        else:\n",
    "            # filtrar\n",
    "            if metadata[\"filtros\"] not in include:\n",
    "                ratings_user[idx] = -1\n",
    "\n",
    "            # potenciar\n",
    "            if metadata[\"filtros\"] in enhance:\n",
    "                ratings_user[idx] += bias\n",
    "    \n",
    "        pass\n",
    "    \"\"\"\n",
    "\n",
    "    # sort ratings\n",
    "    ratings_user_sorted:list = ratings_user.copy()\n",
    "    ratings_user_sorted = ratings_user    \n",
    "    ratings_user_sorted.sort()\n",
    "    ratings_user_sorted = ratings_user_sorted[::-1]\n",
    "    \n",
    "    top_k_recommendations:list = ratings_user_sorted[:k]\n",
    "    \n",
    "    # filter items with rating 0\n",
    "    filtered = list(filter(lambda x: x!=0, top_k_recommendations))\n",
    "    \n",
    "    clean_top_k:list = []\n",
    "    \n",
    "    for rating in filtered:        \n",
    "        idx = ratings_user.index(rating)\n",
    "        item_id = list(itemIndexes.keys())[idx]\n",
    "        clean_top_k.append((item_id,rating))\n",
    "        ratings_user[idx] = -1\n",
    "            \n",
    "    if len(clean_top_k) < k:\n",
    "        ## add popular items to top_k\n",
    "        l:int = k - len(clean_top_k) # number of items to add\n",
    "        \n",
    "        # get popular L items, excluding items in clean_top_k\n",
    "        _exclude:list = exclude.extend([k for k, score in clean_top_k]) \n",
    "        top_l_movies = getTopLMovies(preds, l, exclude=_exclude)\n",
    "        clean_top_k.extend(top_l_movies)\n",
    "        \n",
    "    return clean_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c1d1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_k_items_to_user(preds,770988,10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fde46ced",
   "metadata": {},
   "source": [
    "## [3.c] Recomendar items dado otro item\n",
    "\n",
    "Utiliza la matriz de co-ocurrencia $C$ o de similaridad $S$ para elegir los índices con mayor similitud de la fila/columna del item dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad15e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_k_items(group_id:int,\n",
    "                              k:int,\n",
    "                              include=[],\n",
    "                              exclude=[],\n",
    "                              enhance=[],\n",
    "                             )->np.ndarray:\n",
    "    \n",
    "    global itemIndexes\n",
    "    global invertedItemIndexes\n",
    "    global S\n",
    "    global preds      \n",
    "    \n",
    "    itemIndex = itemIndexes[group_id][\"index\"]\n",
    "    \n",
    "    # item2item = [(similarity, index_in_S), ..., ]\n",
    "    # lo uso asi porque despues elimino elementos y necesito recuperar el index original\n",
    "    item2item:list = [\n",
    "        (similarity, i) for i, similarity in enumerate(list(S[itemIndex].toarray()[0]))\n",
    "    ]    \n",
    "        \n",
    "    # eliminamos al elemento del que se buscan los similares\n",
    "    item2item.pop(itemIndex)\n",
    "    \n",
    "    ## filtro y enhance\n",
    "    \"\"\"\n",
    "    bias = 10\n",
    "    for s, i in item2item:\n",
    "        item = invertedItemIndexes[i]\n",
    "        metadata = item[\"metadata\"]\n",
    "        \n",
    "        # filtrar\n",
    "        if metadata[\"filtros\"] not in include:\n",
    "            item2item[i] = -1\n",
    "        \n",
    "        # potenciar\n",
    "        if metadata[\"filtros\"] in enhance:\n",
    "            item2item[i] += bias\n",
    "        \n",
    "        pass\n",
    "    \"\"\"\n",
    "    \n",
    "    # agarro items similares\n",
    "    recommendations:list = []\n",
    "    MAX:int = -1    \n",
    "    while (MAX != 0) and (len(recommendations) < k):\n",
    "        # agarro la tupla más vista\n",
    "        tuple_most_similar = getBestTuple(item2item)\n",
    "        MAX, indexC = tuple_most_similar      \n",
    "        \n",
    "        # la agrego a las recomendaciones\n",
    "        # si no tiene scoring 0 y no esta en las que hay que excluir\n",
    "        g_id:int = invertedItemIndexes[tuple_most_similar[1]]\n",
    "        \n",
    "        if MAX != 0 and (g_id not in exclude): \n",
    "            recommendations.append(tuple_most_similar)\n",
    "            item2item.remove(tuple_most_similar) \n",
    "            \n",
    "        if g_id in exclude:\n",
    "            item2item.remove(tuple_most_similar)\n",
    "    \n",
    "    # los dejo en el formato valido \n",
    "    clean_top_k:list = []\n",
    "    for n_views, index in recommendations:\n",
    "        rec = (invertedItemIndexes[index], n_views)\n",
    "        clean_top_k.append(rec)\n",
    "    \n",
    "    # si le faltan elementos, agrego los restantes con los mas populares\n",
    "    if len(clean_top_k) < k:\n",
    "        \n",
    "        print(\"Agregando populares\")\n",
    "\n",
    "        # add popular items to top_k\n",
    "        l:int = k - len(clean_top_k) # number of items to add\n",
    " \n",
    "        # get popular L items, excluding items in clean_top_k\n",
    "        _exclude:list = exclude.extend([k for k, score in clean_top_k])\n",
    "        top_l_movies = getTopLMovies(preds, l, exclude=_exclude)\n",
    "\n",
    "        clean_top_k.extend(top_l_movies)\n",
    "    \n",
    "    return clean_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a7375644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(834946, 27.0),\n",
       " (690537, 25.0),\n",
       " (835071, 24.0),\n",
       " (690812, 23.0),\n",
       " (907268, 23.0),\n",
       " (591740, 21.0),\n",
       " (790961, 20.0),\n",
       " (728118, 17.0),\n",
       " (835152, 17.0),\n",
       " (790938, 16.0)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_similar_k_items(group_id=526833, k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "210db575",
   "metadata": {},
   "source": [
    "### Auxiliares para entender los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "eebe6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_mas_popular(C:np.ndarray) -> int:\n",
    "    \n",
    "    global itemIndexes\n",
    "    \n",
    "    M:int = C.shape[1] # numero de items en C\n",
    "    views_per_item = [C[i].sum() for i in range (M)]\n",
    "    n_views_most_watched = max(views_per_item)\n",
    "    most_watched_index = views_per_item.index(n_views_most_watched)\n",
    "    \n",
    "    itemKey = list(itemIndexes.keys())[most_watched_index]\n",
    "    \n",
    "    return itemKey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95bb5610",
   "metadata": {},
   "source": [
    "## 4. Testing:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97d796ec",
   "metadata": {},
   "source": [
    "### Interpretar recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f6fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elegirItemAlAzar() -> int:\n",
    "    global itemIndexes\n",
    "    N = len(itemIndexes)\n",
    "    return list(itemIndexes.keys())[np.random.randint(0,N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3210a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describirItem(group_id:int) -> tuple:\n",
    "\n",
    "    # Dado un group_id,\n",
    "    # Describe que sus caracteristicas principales\n",
    "    \n",
    "    url = leerMetadata(group_id)\n",
    "    \n",
    "    resp = requests.get(url).json()\n",
    "    proveedor = resp[\"_source\"][\"NOMBRE_PROVEEDOR\"]\n",
    "    nombre = resp[\"_source\"][\"TITULO_ESP\"]\n",
    "    genero = resp[\"_source\"][\"INFO_GENERO\"][0][\"GENERO_ESP\"]\n",
    "    descripcion = resp[\"_source\"][\"DESCRIPCION_ESP\"]\n",
    " \n",
    "    return group_id, nombre, genero, proveedor, descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be1bee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretar_recomendaciones(group_id:int, recommendations:list) -> pd.DataFrame:\n",
    "    \n",
    "    print(f\"item modelo:\")\n",
    "    print(describirItem(group_id))\n",
    "    \n",
    "    recs:list = []\n",
    "    \n",
    "    for g_id, score in recommendations:    \n",
    "        values = describirItem(g_id)\n",
    "        recs.append(values)\n",
    "        \n",
    "    descr = pd.DataFrame(recs, columns=[\"id\", \"nombre\", \"genero\", \"proveedor\", \"descripcion\"])\n",
    "    \n",
    "    return descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5da5192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item modelo:\n",
      "(905117, 'Ugly Americans', 'comedia', 'PARAMOUNT', 'Mark ayuda a diferentes criaturas a que se adapten a la vida de Nueva York.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>genero</th>\n",
       "      <th>proveedor</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909791</td>\n",
       "      <td>La casa de los dibujos</td>\n",
       "      <td>comedia</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>Los ocho personajes llegan y se conocen. La pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724938</td>\n",
       "      <td>Angry Birds: La película</td>\n",
       "      <td>Animación</td>\n",
       "      <td>AMCO</td>\n",
       "      <td>¿Por qué están tan enojados estos pajaritos? C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919826</td>\n",
       "      <td>Bob Esponja</td>\n",
       "      <td>Infantil</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>Bob Esponja construye un puesto para hacer bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>617635</td>\n",
       "      <td>Son como niños</td>\n",
       "      <td>Comedia</td>\n",
       "      <td>AMCO</td>\n",
       "      <td>Aunque hayan crecido, estos cinco amigos siemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>659627</td>\n",
       "      <td>Naruto</td>\n",
       "      <td>Series</td>\n",
       "      <td>AMCO</td>\n",
       "      <td>Conoce a Naruto Uzumaki, un travieso niño que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>921692</td>\n",
       "      <td>Los Pingüinos de Madagascar</td>\n",
       "      <td>Infantil</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>El doctor del zoológico está vacunando a los p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>888314</td>\n",
       "      <td>Victorious</td>\n",
       "      <td>comedia</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>Tori descubre que sus amigos han estado yendo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>573860</td>\n",
       "      <td>Niñas mal</td>\n",
       "      <td>Comedia</td>\n",
       "      <td>AMCO</td>\n",
       "      <td>Comedia mexicana donde una adolescente rebelde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>888262</td>\n",
       "      <td>Victorious</td>\n",
       "      <td>comedia</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>Tori acepta ayudar a Jade a buscar un teatro. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>883694</td>\n",
       "      <td>Grease</td>\n",
       "      <td>Drama</td>\n",
       "      <td>PARAMOUNT</td>\n",
       "      <td>John Travolta consolidó su prestigio como el a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        nombre     genero  proveedor   \n",
       "0  909791        La casa de los dibujos    comedia  PARAMOUNT  \\\n",
       "1  724938      Angry Birds: La película  Animación       AMCO   \n",
       "2  919826                   Bob Esponja   Infantil  PARAMOUNT   \n",
       "3  617635                Son como niños    Comedia       AMCO   \n",
       "4  659627                        Naruto     Series       AMCO   \n",
       "5  921692  Los Pingüinos de Madagascar    Infantil  PARAMOUNT   \n",
       "6  888314                    Victorious    comedia  PARAMOUNT   \n",
       "7  573860                     Niñas mal    Comedia       AMCO   \n",
       "8  888262                    Victorious    comedia  PARAMOUNT   \n",
       "9  883694                        Grease      Drama  PARAMOUNT   \n",
       "\n",
       "                                         descripcion  \n",
       "0  Los ocho personajes llegan y se conocen. La pr...  \n",
       "1  ¿Por qué están tan enojados estos pajaritos? C...  \n",
       "2  Bob Esponja construye un puesto para hacer bur...  \n",
       "3  Aunque hayan crecido, estos cinco amigos siemp...  \n",
       "4  Conoce a Naruto Uzumaki, un travieso niño que ...  \n",
       "5  El doctor del zoológico está vacunando a los p...  \n",
       "6  Tori descubre que sus amigos han estado yendo ...  \n",
       "7  Comedia mexicana donde una adolescente rebelde...  \n",
       "8  Tori acepta ayudar a Jade a buscar un teatro. ...  \n",
       "9  John Travolta consolidó su prestigio como el a...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_id = elegirItemAlAzar()\n",
    "recs = recommend_similar_k_items(group_id=g_id, k=10, exclude=[])\n",
    "res = interpretar_recomendaciones(g_id, recs)\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcaac572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668312"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cantidad_interacciones_usadas(items_viewers:dict) -> int:\n",
    "    contador:int = 0\n",
    "    for k,v in items_viewers.items():\n",
    "        contador += len(v)\n",
    "    return contador\n",
    "\n",
    "cantidad_interacciones_usadas(items_viewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1cfbaf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# usuarios que vieron A: 252\n",
      "# usuarios que vieron B:  128\n",
      "# usuarios que vieron A y B:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 921352\n",
    "b = 660870\n",
    "\n",
    "viewers_A = items_viewers[a]\n",
    "viewers_B = items_viewers[b]\n",
    "\n",
    "viewers_AB = viewers_A.intersection(viewers_B)\n",
    "\n",
    "print(\"# usuarios que vieron A:\", len(viewers_A))\n",
    "print(\"# usuarios que vieron B: \", len(viewers_B))\n",
    "print(\"# usuarios que vieron A y B: \", len(viewers_AB))\n",
    "\n",
    "index_A = itemIndexes[a][\"index\"] # indice en C\n",
    "index_B = itemIndexes[b][\"index\"] # indice en C\n",
    "\n",
    "C[index_A, index_B]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47a96ca3",
   "metadata": {},
   "source": [
    "### ¿Recomienda algun contenido no visto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b9bc7d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendo un item no visto! :) 82313217 770988\n"
     ]
    }
   ],
   "source": [
    "users:set = set()\n",
    "for key in items_viewers.keys():\n",
    "    users = users.union(items_viewers[key])\n",
    "    \n",
    "stop = False\n",
    "for item_id in items_viewers.keys():\n",
    "    users_viewed_item:set = set(items_viewers[item_id])\n",
    "    for us in users-users_viewed_item:\n",
    "        if rating(us, item_id) != 0:\n",
    "            print(\"Recomendo un item no visto! :)\", us, item_id)\n",
    "            stop = True\n",
    "            break\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75650c1",
   "metadata": {},
   "source": [
    "### Testing por ECM:\n",
    "\n",
    "La idea es que recorro todas las interacciones (usuario, contenido) del DataFrame que queda como test. \n",
    "\n",
    "Se considera que al usuario ($j$) se le recomienda el item ($i$) en el caso de test cuando el estimador del rating de ese contenido para el usuario ($\\hat{Y_{(ij)}}$) es mayor a la media de los ratings de las demas peliculas para el usuario $j$: $\\mu_{\\hat{Y_{j}}} = \\sum_{k=1}^{M} k \\hat{Y_{(kj)}}$. \n",
    "\n",
    "Luego el $ECM$ queda: \n",
    "\n",
    "$ECM(\\hat{Y}, Y) = \\sum_{i,j \\in TEST | \\hat{Y_{(ij)}} < \\mu_{\\hat{Y_{j}}}} (1-\\hat{Y_{(ij)}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(preds:np.ndarray, test_y:DataFrame) -> float:\n",
    "    \n",
    "    # args:\n",
    "    #  preds: matriz N x M con las predicciones de rating  \n",
    "    #  test_y: dataframe con las interacciones no incluidas en el training   \n",
    "    \n",
    "    global itemIndexes\n",
    "    global userIndexes\n",
    "    \n",
    "    invertedItemIndexes:dict = {v: k for k, v in itemIndexes.items()}\n",
    "    error:float = 0\n",
    "    \n",
    "    for interaction in test_y.collect():\n",
    "        user_id, group_id, event_time = decode_interaction(interaction)\n",
    "        \n",
    "        item_index = itemIndexes[group_id]\n",
    "        user_index = userIndexes[user_id]\n",
    "        \n",
    "        MEAN_RATINGS_USER = preds[user_index:].mean()\n",
    "        MAX_RATING_USER = preds[user_index:].max()\n",
    "        rating = preds[user_index, item_index]\n",
    "        \n",
    "        if rating < MEAN_RATINGS_USER:\n",
    "            scala_pred = rating / MAX_RATING_USER\n",
    "            error += (1 - scala_pred)**2\n",
    "        else:\n",
    "            ## se presupone que podría ser recomendado\n",
    "            # print(rating, MEAN_MOVIE)\n",
    "            pass\n",
    "        \n",
    "    return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM(preds, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
