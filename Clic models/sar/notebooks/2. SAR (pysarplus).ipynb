{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos librerias necesarias\n",
    "> Divididas por uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark DF\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, DataFrame\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from pysarplus import SARPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- --------\n",
      "ansiwrap            0.8.4\n",
      "asttokens           2.2.1\n",
      "attrs               23.1.0\n",
      "backcall            0.2.0\n",
      "Bottleneck          1.3.7\n",
      "category-encoders   1.3.0\n",
      "certifi             2023.5.7\n",
      "charset-normalizer  3.1.0\n",
      "click               8.1.3\n",
      "comm                0.1.3\n",
      "contourpy           1.0.7\n",
      "cornac              1.15.4\n",
      "cycler              0.11.0\n",
      "debugpy             1.6.7\n",
      "decorator           5.1.1\n",
      "entrypoints         0.4\n",
      "exceptiongroup      1.1.1\n",
      "executing           1.2.0\n",
      "fastjsonschema      2.16.3\n",
      "filelock            3.12.0\n",
      "fonttools           4.39.4\n",
      "fsspec              2023.5.0\n",
      "huggingface-hub     0.14.1\n",
      "hypothesis          6.75.3\n",
      "idna                3.4\n",
      "importlib-metadata  6.6.0\n",
      "importlib-resources 5.12.0\n",
      "ipykernel           6.23.1\n",
      "ipython             8.13.2\n",
      "jedi                0.18.2\n",
      "Jinja2              3.0.3\n",
      "joblib              1.2.0\n",
      "jsonschema          4.17.3\n",
      "jupyter_client      8.2.0\n",
      "jupyter_core        5.3.0\n",
      "kiwisolver          1.4.4\n",
      "lightfm             1.17\n",
      "lightgbm            3.3.5\n",
      "llvmlite            0.40.0\n",
      "MarkupSafe          2.1.2\n",
      "matplotlib          3.7.1\n",
      "matplotlib-inline   0.1.6\n",
      "memory-profiler     0.61.0\n",
      "mpmath              1.3.0\n",
      "multimethod         1.9.1\n",
      "mypy-extensions     1.0.0\n",
      "nbclient            0.7.4\n",
      "nbformat            5.8.0\n",
      "nest-asyncio        1.5.6\n",
      "nltk                3.8.1\n",
      "numba               0.57.0\n",
      "numpy               1.24.3\n",
      "packaging           23.1\n",
      "pandas              1.5.3\n",
      "pandera             0.15.1\n",
      "papermill           2.4.0\n",
      "parso               0.8.3\n",
      "patsy               0.5.3\n",
      "pexpect             4.8.0\n",
      "pickleshare         0.7.5\n",
      "Pillow              9.5.0\n",
      "pip                 22.0.2\n",
      "platformdirs        3.5.1\n",
      "powerlaw            1.5\n",
      "prompt-toolkit      3.0.38\n",
      "psutil              5.9.5\n",
      "ptyprocess          0.7.0\n",
      "pure-eval           0.2.2\n",
      "py4j                0.10.9.7\n",
      "pyarrow             12.0.0\n",
      "pybind11            2.10.4\n",
      "pydantic            1.10.7\n",
      "Pygments            2.15.1\n",
      "pyparsing           3.0.9\n",
      "pyrsistent          0.19.3\n",
      "pysarplus           0.6.6\n",
      "pyspark             3.4.0\n",
      "python-dateutil     2.8.2\n",
      "pytz                2023.3\n",
      "PyYAML              5.4.1\n",
      "pyzmq               25.0.2\n",
      "recommenders        1.1.1\n",
      "regex               2023.5.5\n",
      "requests            2.30.0\n",
      "retrying            1.3.4\n",
      "scikit-learn        1.0.2\n",
      "scikit-surprise     1.1.3\n",
      "scipy               1.10.1\n",
      "scrapbook           0.5.0\n",
      "seaborn             0.12.2\n",
      "setuptools          59.6.0\n",
      "six                 1.16.0\n",
      "sortedcontainers    2.4.0\n",
      "stack-data          0.6.2\n",
      "statsmodels         0.14.0\n",
      "tenacity            8.2.2\n",
      "textwrap3           0.9.2\n",
      "threadpoolctl       3.1.0\n",
      "timer               0.2.2\n",
      "tokenizers          0.13.3\n",
      "tornado             6.3.2\n",
      "tqdm                4.65.0\n",
      "traitlets           5.9.0\n",
      "transformers        4.29.2\n",
      "typeguard           4.0.0\n",
      "typing_extensions   4.5.0\n",
      "typing-inspect      0.8.0\n",
      "urllib3             2.0.2\n",
      "wcwidth             0.2.6\n",
      "wheel               0.37.1\n",
      "wrapt               1.15.0\n",
      "zipp                3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluators\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos\n",
    "> Leemos los datos del Cassandra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_options = {\"table\": \"view_events\", \"keyspace\": \"clarovideo\"}\n",
    "df = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**load_options).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160708"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.withColumn(\"view\", lit(1))\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = dataset.randomSplit([.8, .2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar el modelo\n",
    "> Inicializacion del modelo SARPLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"col_user\": \"user_id\",\n",
    "    \"col_item\": \"group_id\",\n",
    "    \"col_rating\": \"view\",\n",
    "    \"col_timestamp\": \"event_time\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARPlus(\n",
    "    spark,\n",
    "    similarity_type=\"jaccard\",\n",
    "    timedecay_formula=True,\n",
    "    time_decay_coefficient=30,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del modelo\n",
    "\n",
    "> model.fit(train:DataFrame) arma en spark un DataFrame con una columna del tipo |User|Item|Score|, segun la multiplicacion de las matrices de afinidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_915613/2514783072.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"* Time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timer' is not defined"
     ]
    }
   ],
   "source": [
    "with timer() as t:\n",
    "    model.fit(train)\n",
    "print(\"* Time: \", t.elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recomendaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TOP_K = 4\n",
    "recommendations = model.recommend_k_items(test, top_k=TOP_K, remove_seen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+\n",
      "|user_id|group_id|               score|\n",
      "+-------+--------+--------------------+\n",
      "|2047319|  769573|  0.9862464188748867|\n",
      "|2047319|  933034| 0.04109360078645361|\n",
      "|2047319| 1108920| 0.02817846911071105|\n",
      "|2047319|  966910|0.014720095804102787|\n",
      "|2077551|  834948|  1.7721307068269678|\n",
      "|2077551|  835061|  1.7528912821296077|\n",
      "|2077551|  835081|   1.637055649710639|\n",
      "|2077551|  835088|  1.6094968218326975|\n",
      "|2158715| 1032512|  0.9940463520546271|\n",
      "|2158715| 1038292| 0.49702317602731355|\n",
      "|2158715| 1038280| 0.37276738202048515|\n",
      "|2158715|  835011|  0.1656743920091045|\n",
      "|2160345| 1112156|  0.9893261613904413|\n",
      "|2160345| 1112950|  0.3297753871301471|\n",
      "|2160345| 1112953| 0.24733154034761032|\n",
      "|2160345| 1113707| 0.19786523227808828|\n",
      "|2283039| 1097586|  2.9529769995234973|\n",
      "|2283039| 1101689|  2.9529769995234973|\n",
      "|2283039| 1100203|  2.9529769995234973|\n",
      "|2283039| 1117512|  0.9806659687470285|\n",
      "+-------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 45:>                                                         (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Bajo la logica del SAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__base__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(col_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m               col_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m               col_rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m               col_prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m               relevancy_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m               k\u001b[38;5;241m=\u001b[39mTOPK)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# eval_map = map_at_k(*args, **kwargs)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# eval_ndcg = ndcg_at_k(*args, **kwargs)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m eval_precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m eval_recall \u001b[38;5;241m=\u001b[39m recall_at_k(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Workspace/pyspark-recommender/test/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:454\u001b[0m, in \u001b[0;36mprecision_at_k\u001b[0;34m(rating_true, rating_pred, col_user, col_item, col_rating, col_prediction, relevancy_method, k, threshold)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_at_k\u001b[39m(\n\u001b[1;32m    419\u001b[0m     rating_true,\n\u001b[1;32m    420\u001b[0m     rating_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mDEFAULT_THRESHOLD,\n\u001b[1;32m    428\u001b[0m ):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Precision at K.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m        float: precision at k (min=0, max=1)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     df_hit, df_hit_count, n_users \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_ranking_true_pred\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrating_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrating_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_item\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_rating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_rating\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelevancy_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelevancy_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_hit\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Workspace/pyspark-recommender/test/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:76\u001b[0m, in \u001b[0;36m_check_column_dtypes.<locals>.check_column_dtypes_wrapper\u001b[0;34m(rating_true, rating_pred, col_user, col_item, col_rating, col_prediction, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_columns(rating_pred, [col_user, col_item, col_prediction]):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing columns in predicted rating DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_same_base_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcol_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_item\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in provided DataFrames are not the same datatype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m     82\u001b[0m     rating_true\u001b[38;5;241m=\u001b[39mrating_true,\n\u001b[1;32m     83\u001b[0m     rating_pred\u001b[38;5;241m=\u001b[39mrating_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/Workspace/pyspark-recommender/test/lib/python3.9/site-packages/recommenders/datasets/pandas_df_utils.py:405\u001b[0m, in \u001b[0;36mhas_same_base_dtype\u001b[0;34m(df_1, df_2, columns)\u001b[0m\n\u001b[1;32m    403\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__base__\u001b[49m \u001b[38;5;241m!=\u001b[39m df_2[column]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39m__base__:\n\u001b[1;32m    406\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m do not have the same base datatype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(column))\n\u001b[1;32m    407\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/column.py:668\u001b[0m, in \u001b[0;36mColumn.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03mAn expression that gets an item at position ``ordinal`` out of a list,\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03mor gets an item by key out of a dict.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m+------+\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(item)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n",
      "\u001b[0;31mAttributeError\u001b[0m: __base__"
     ]
    }
   ],
   "source": [
    "args = [test, top_k]\n",
    "kwargs = dict(col_user='user_id', \n",
    "              col_item='group_id', \n",
    "              col_rating='view', \n",
    "              col_prediction='score', \n",
    "              relevancy_method='top_k', \n",
    "              k=TOPK)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model:\",\n",
    "      f\"Top K:\\t\\t {TOP_K}\",\n",
    "      f\"MAP:\\t\\t {eval_map:f}\",\n",
    "      f\"NDCG:\\t\\t {eval_ndcg:f}\",\n",
    "      f\"Precision@K:\\t {eval_precision:f}\",\n",
    "      f\"Recall@K:\\t {eval_recall:f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Como interseccion del test y las recomendaciones:\n",
    "UsersInRecs = UsersInTrain $\\cap$ UsersInTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "users_in_recs = set(recommendations.rdd.map(lambda x: x.user_id).collect()) \n",
    "print(users_in_recs == users_in_tests.intersection(users_in_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Views = dict() # user_id: [itemIds seen in test]\n",
    "\n",
    "for user_id in list(users_in_recs):\n",
    "    user_views = set(test_data.where(test_data.user_id == user_id).\\\n",
    "                      rdd.map(lambda x: x.group_id).collect())\n",
    "    Views.update({user_id : user_views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{44603296: {553221, 554102},\n",
       " 29080963: {1114857, 1114907},\n",
       " 38198886: {1109110},\n",
       " 79273447: {1119257},\n",
       " 66520777: {583163},\n",
       " 81934995: {925522},\n",
       " 72086164: {952535, 954052},\n",
       " 61385205: {928978},\n",
       " 77273878: {1109700},\n",
       " 29888861: {1071326, 1072130}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommendations = dict()\n",
    "\n",
    "for user_id in list(users_in_recs):\n",
    "    user_views = set(recommendations.where(recommendations.user_id == user_id).\\\n",
    "                      rdd.map(lambda x: x.group_id).collect())\n",
    "    Recommendations.update({user_id : user_views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{44603296: {553981},\n",
       " 29080963: {1113411, 1113412},\n",
       " 38198886: {1110700},\n",
       " 79273447: {610966, 973252},\n",
       " 66520777: {583184, 583188},\n",
       " 81934995: {1060889, 1060890},\n",
       " 72086164: {924975, 925859},\n",
       " 61385205: {929072},\n",
       " 77273878: {1108217, 1111412},\n",
       " 29888861: {1075184, 1075190}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_sar_test(Views:dict, Recommendations:dict) -> float:\n",
    "    error = 0\n",
    "    for key in Views.keys():\n",
    "        views = Views[key]\n",
    "        recs = Recommendations[key]\n",
    "        ok = len(recs.intersection(views))\n",
    "        if ok > 0:\n",
    "            error += len(views ^ recs) / ok\n",
    "        else:\n",
    "            error += len(views ^ recs) \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_sar_test(Views,Recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
